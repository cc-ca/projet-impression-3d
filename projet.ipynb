{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import random\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://drive.google.com/drive/folders/1_MU7jTR0kTt8MFQYrUzWiWc6uM-BHG_9?usp=drive_link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(dataset_path):\n",
    "    data = []\n",
    "    labels = []\n",
    "\n",
    "    for folder in os.listdir(dataset_path):\n",
    "        folder_path = os.path.join(dataset_path, folder)\n",
    "        if os.path.isdir(folder_path):\n",
    "            label = 1 if folder.lower() == 'ok' else 0  # 1 for OK, 0 for defects\n",
    "            for filename in os.listdir(folder_path):\n",
    "                img_path = os.path.join(folder_path, filename)\n",
    "                img = cv2.imread(img_path)\n",
    "                img = cv2.resize(img, (128, 128))  # Adjust the size as needed\n",
    "                data.append(img)\n",
    "                labels.append(label)\n",
    "                \n",
    "    data = np.array(data) / 255.0  # Normalize pixel values\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    return data, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = 'dataset'\n",
    "data, labels = load_data(dataset_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "324\n"
     ]
    }
   ],
   "source": [
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 3)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "9/9 [==============================] - 4s 295ms/step - loss: 0.4042 - accuracy: 0.8108 - val_loss: 1.0875 - val_accuracy: 0.4615\n",
      "Epoch 2/10\n",
      "9/9 [==============================] - 3s 278ms/step - loss: 0.3580 - accuracy: 0.8571 - val_loss: 0.4670 - val_accuracy: 0.7846\n",
      "Epoch 3/10\n",
      "9/9 [==============================] - 2s 252ms/step - loss: 0.2725 - accuracy: 0.8996 - val_loss: 0.3408 - val_accuracy: 0.8000\n",
      "Epoch 4/10\n",
      "9/9 [==============================] - 2s 247ms/step - loss: 0.3005 - accuracy: 0.8958 - val_loss: 0.5987 - val_accuracy: 0.7385\n",
      "Epoch 5/10\n",
      "9/9 [==============================] - 2s 238ms/step - loss: 0.2109 - accuracy: 0.9305 - val_loss: 0.6808 - val_accuracy: 0.7231\n",
      "Epoch 6/10\n",
      "9/9 [==============================] - 2s 245ms/step - loss: 0.1723 - accuracy: 0.9382 - val_loss: 0.8069 - val_accuracy: 0.6769\n",
      "Epoch 7/10\n",
      "9/9 [==============================] - 2s 250ms/step - loss: 0.1443 - accuracy: 0.9537 - val_loss: 0.4313 - val_accuracy: 0.8000\n",
      "Epoch 8/10\n",
      "9/9 [==============================] - 2s 237ms/step - loss: 0.1159 - accuracy: 0.9730 - val_loss: 0.3467 - val_accuracy: 0.8615\n",
      "Epoch 9/10\n",
      "9/9 [==============================] - 2s 249ms/step - loss: 0.0914 - accuracy: 0.9807 - val_loss: 0.6483 - val_accuracy: 0.7385\n",
      "Epoch 10/10\n",
      "9/9 [==============================] - 2s 234ms/step - loss: 0.0669 - accuracy: 0.9846 - val_loss: 1.0008 - val_accuracy: 0.6154\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x139b9b1a6e0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(data, labels, epochs=10, validation_split=0.20)\n",
    "\n",
    "#model.save('defect_detection_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess_image(image_path):\n",
    "    img = cv2.imread(image_path)\n",
    "    img = cv2.resize(img, (128, 128))  # Assurez-vous que la taille correspond à celle utilisée lors de l'entraînement\n",
    "    img = img / 255.0  # Normalisez les valeurs des pixels\n",
    "    img = np.expand_dims(img, axis=0)  # Ajoutez une dimension pour représenter le lot (batch)\n",
    "\n",
    "    return img\n",
    "\n",
    "def predict_defect(model, image_path):\n",
    "    preprocessed_img = load_and_preprocess_image(image_path)\n",
    "    prediction = model.predict(preprocessed_img)\n",
    "\n",
    "    # Interprétez la prédiction (1 signifie \"OK\", 0 signifie \"défaut\")\n",
    "    if prediction[0, 0] > 0.5:\n",
    "        return \"OK\"\n",
    "    else:\n",
    "        return \"Défaut\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.8.1) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\resize.cpp:4062: error: (-215:Assertion failed) !ssize.empty() in function 'cv::resize'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\totol\\Mon Drive\\projet impression 3d\\projet.ipynb Cellule 9\u001b[0m line \u001b[0;36m6\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/totol/Mon%20Drive/projet%20impression%203d/projet.ipynb#X11sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Charger le modèle préalablement entraîné\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/totol/Mon%20Drive/projet%20impression%203d/projet.ipynb#X11sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39m#model = keras.models.load_model('defect_detection_model.h5')\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/totol/Mon%20Drive/projet%20impression%203d/projet.ipynb#X11sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/totol/Mon%20Drive/projet%20impression%203d/projet.ipynb#X11sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# Exemple d'utilisation\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/totol/Mon%20Drive/projet%20impression%203d/projet.ipynb#X11sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m image_path_to_predict \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mok.jpg\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/totol/Mon%20Drive/projet%20impression%203d/projet.ipynb#X11sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m result \u001b[39m=\u001b[39m predict_defect(model, image_path_to_predict)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/totol/Mon%20Drive/projet%20impression%203d/projet.ipynb#X11sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mPrédiction pour \u001b[39m\u001b[39m{\u001b[39;00mimage_path_to_predict\u001b[39m}\u001b[39;00m\u001b[39m: \u001b[39m\u001b[39m{\u001b[39;00mresult\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;32mc:\\Users\\totol\\Mon Drive\\projet impression 3d\\projet.ipynb Cellule 9\u001b[0m line \u001b[0;36m1\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/totol/Mon%20Drive/projet%20impression%203d/projet.ipynb#X11sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredict_defect\u001b[39m(model, image_path):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/totol/Mon%20Drive/projet%20impression%203d/projet.ipynb#X11sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     preprocessed_img \u001b[39m=\u001b[39m load_and_preprocess_image(image_path)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/totol/Mon%20Drive/projet%20impression%203d/projet.ipynb#X11sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     prediction \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict(preprocessed_img)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/totol/Mon%20Drive/projet%20impression%203d/projet.ipynb#X11sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     \u001b[39m# Interprétez la prédiction (1 signifie \"OK\", 0 signifie \"défaut\")\u001b[39;00m\n",
      "\u001b[1;32mc:\\Users\\totol\\Mon Drive\\projet impression 3d\\projet.ipynb Cellule 9\u001b[0m line \u001b[0;36m3\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/totol/Mon%20Drive/projet%20impression%203d/projet.ipynb#X11sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload_and_preprocess_image\u001b[39m(image_path):\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/totol/Mon%20Drive/projet%20impression%203d/projet.ipynb#X11sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     img \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mimread(image_path)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/totol/Mon%20Drive/projet%20impression%203d/projet.ipynb#X11sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     img \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39;49mresize(img, (\u001b[39m255\u001b[39;49m, \u001b[39m255\u001b[39;49m))  \u001b[39m# Assurez-vous que la taille correspond à celle utilisée lors de l'entraînement\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/totol/Mon%20Drive/projet%20impression%203d/projet.ipynb#X11sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     img \u001b[39m=\u001b[39m img \u001b[39m/\u001b[39m \u001b[39m255.0\u001b[39m  \u001b[39m# Normalisez les valeurs des pixels\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/totol/Mon%20Drive/projet%20impression%203d/projet.ipynb#X11sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     img \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mexpand_dims(img, axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)  \u001b[39m# Ajoutez une dimension pour représenter le lot (batch)\u001b[39;00m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.8.1) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\resize.cpp:4062: error: (-215:Assertion failed) !ssize.empty() in function 'cv::resize'\n"
     ]
    }
   ],
   "source": [
    "# Charger le modèle préalablement entraîné\n",
    "#model = keras.models.load_model('defect_detection_model.h5')\n",
    "\n",
    "# Exemple d'utilisation\n",
    "image_path_to_predict = 'ok.jpg'\n",
    "result = predict_defect(model, image_path_to_predict)\n",
    "print(f\"Prédiction pour {image_path_to_predict}: {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 82ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n"
     ]
    }
   ],
   "source": [
    "resultf=\"\"\n",
    "for filename in os.listdir(\"testperso\"):\n",
    "    #print(filename)\n",
    "    result = predict_defect(model, \"testperso/\" + filename)\n",
    "    resultf= resultf + \"prédiction pour\"+ filename + \" : \"+ str(result) +\"\\n\"\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prédiction pourWIN_20231010_15_02_24_Pro.jpg : Défaut\n",
      "prédiction pourWIN_20231010_15_02_40_Pro.jpg : Défaut\n",
      "prédiction pourWIN_20231010_15_03_00_Pro.jpg : Défaut\n",
      "prédiction pourWIN_20231010_15_03_09_Pro.jpg : Défaut\n",
      "prédiction pourWIN_20231010_15_03_11_Pro.jpg : Défaut\n",
      "prédiction pourWIN_20231010_15_03_18_Pro.jpg : Défaut\n",
      "prédiction pourWIN_20231010_15_03_24_Pro.jpg : OK\n",
      "prédiction pourWIN_20231010_15_03_29_Pro.jpg : Défaut\n",
      "prédiction pourWIN_20231010_15_03_56_Pro.jpg : Défaut\n",
      "prédiction pourWIN_20231010_15_03_58_Pro.jpg : Défaut\n",
      "prédiction pourWIN_20231010_15_04_02_Pro.jpg : Défaut\n",
      "prédiction pourWIN_20231010_15_04_05_Pro.jpg : Défaut\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print (resultf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "multi classes-----------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess_image(image_path):\n",
    "    img = cv2.imread(image_path)\n",
    "    img = cv2.resize(img, (255, 255))  # Assurez-vous que la taille correspond à celle utilisée lors de l'entraînement\n",
    "    img = img / 255.0  # Normalisez les valeurs des pixels\n",
    "    img = np.expand_dims(img, axis=0)  # Ajoutez une dimension pour représenter le lot (batch)\n",
    "\n",
    "    return img\n",
    "\n",
    "def predict_defect(model, image_path):\n",
    "    preprocessed_img = load_and_preprocess_image(image_path)\n",
    "    prediction = model.predict(preprocessed_img)\n",
    "\n",
    "    # Interprétez la prédiction (1 signifie \"OK\", 0 signifie \"défaut\")\n",
    "    if prediction[0, 0] > 0.5:\n",
    "        return \"OK\"\n",
    "    else:\n",
    "        return \"Défaut\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_multi_class(dataset_path):\n",
    "    data = []\n",
    "    labels = []\n",
    "\n",
    "    for folder in os.listdir(dataset_path):\n",
    "        folder_path = os.path.join(dataset_path, folder)\n",
    "        if os.path.isdir(folder_path):\n",
    "            \n",
    "            label = folder.lower()  # Utilisez le nom du dossier comme label\n",
    "            print(label)\n",
    "            for filename in os.listdir(folder_path):\n",
    "                #print(filename)\n",
    "                img_path = os.path.join(folder_path, filename)\n",
    "                img = cv2.imread(img_path)\n",
    "                img = cv2.resize(img, (255, 255))\n",
    "                data.append(img)\n",
    "                labels.append(label)\n",
    "\n",
    "    data = np.array(data) / 255.0\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    return data, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blobs\n",
      "ok\n",
      "spaghetti\n",
      "under exstrosion\n"
     ]
    }
   ],
   "source": [
    "dataset_path = 'dataset'\n",
    "data, labels = load_data_multi_class(dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définir un dictionnaire de mapping catégorie -> numéro\n",
    "categorie_mapping = {\n",
    "    \"blobs\": 0,\n",
    "    \"cracks\": 1,\n",
    "    \"ok\": 2,\n",
    "    \"spaghetti\": 3,\n",
    "    \"stringing\": 4,\n",
    "    \"under exstrosion\": 5\n",
    "}\n",
    "\n",
    "# Utiliser NumPy pour convertir les catégories en numéros\n",
    "labels = np.array([categorie_mapping[c] for c in labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "177\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "print (len(labels))\n",
    "print(labels[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "177\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "combined_data = list(zip(data,labels))\n",
    "\n",
    "# Mélangez la liste combinée\n",
    "random.shuffle(combined_data)\n",
    "\n",
    "# Divisez à nouveau la liste combinée en deux listes distinctes\n",
    "data,labels = zip(*combined_data)\n",
    "\n",
    "labels = np.array(labels)\n",
    "data = np.array(data)\n",
    "print (len(labels))\n",
    "print(labels[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(255, 255, 3)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dropout(0.5),  # Ajout de la couche Dropout\n",
    "    layers.Dense(1024, activation='relu'),\n",
    "    layers.Dropout(0.5),  # Ajout de la couche Dropout\n",
    "    layers.Dense(255, activation='relu'),\n",
    "    layers.Dropout(0.5),  # Ajout de la couche Dropout\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dropout(0.5),  # Ajout d'une autre couche Dropout\n",
    "    layers.Dense(10, activation='softmax')  # Ajustez cela en fonction de votre nombre de classes\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(177, 255, 255, 3)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "15/15 [==============================] - 67s 4s/step - loss: 6.0113 - accuracy: 0.2482 - val_loss: 1.6549 - val_accuracy: 0.5278\n",
      "Epoch 2/10\n",
      " 5/15 [=========>....................] - ETA: 27s - loss: 1.9054 - accuracy: 0.3200"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\totol\\Mon Drive\\projet impression 3d\\projet.ipynb Cellule 21\u001b[0m line \u001b[0;36m1\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/totol/Mon%20Drive/projet%20impression%203d/projet.ipynb#X35sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m model\u001b[39m.\u001b[39mcompile(optimizer\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39madam\u001b[39m\u001b[39m'\u001b[39m, loss\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39msparse_categorical_crossentropy\u001b[39m\u001b[39m'\u001b[39m, metrics\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/totol/Mon%20Drive/projet%20impression%203d/projet.ipynb#X35sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39m# Entraînez le modèle avec des batches de taille 10 par epoch et sauvegardez le meilleur modèle\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/totol/Mon%20Drive/projet%20impression%203d/projet.ipynb#X35sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m model\u001b[39m.\u001b[39;49mfit(data, labels, epochs\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m, validation_split\u001b[39m=\u001b[39;49m\u001b[39m0.20\u001b[39;49m, batch_size\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m, callbacks\u001b[39m=\u001b[39;49m[checkpoint])\n",
      "File \u001b[1;32mc:\\Users\\totol\\miniconda3\\envs\\env2\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\totol\\miniconda3\\envs\\env2\\lib\\site-packages\\keras\\src\\engine\\training.py:1783\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1775\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1776\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1777\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1780\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[0;32m   1781\u001b[0m ):\n\u001b[0;32m   1782\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1783\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   1784\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1785\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\totol\\miniconda3\\envs\\env2\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\totol\\miniconda3\\envs\\env2\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:831\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    828\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    830\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 831\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    833\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    834\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\totol\\miniconda3\\envs\\env2\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:867\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    864\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    865\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    866\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 867\u001b[0m   \u001b[39mreturn\u001b[39;00m tracing_compilation\u001b[39m.\u001b[39;49mcall_function(\n\u001b[0;32m    868\u001b[0m       args, kwds, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_no_variable_creation_config\n\u001b[0;32m    869\u001b[0m   )\n\u001b[0;32m    870\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_config \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    871\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    872\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[0;32m    873\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\Users\\totol\\miniconda3\\envs\\env2\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    137\u001b[0m bound_args \u001b[39m=\u001b[39m function\u001b[39m.\u001b[39mfunction_type\u001b[39m.\u001b[39mbind(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m flat_inputs \u001b[39m=\u001b[39m function\u001b[39m.\u001b[39mfunction_type\u001b[39m.\u001b[39munpack_inputs(bound_args)\n\u001b[1;32m--> 139\u001b[0m \u001b[39mreturn\u001b[39;00m function\u001b[39m.\u001b[39;49m_call_flat(  \u001b[39m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    140\u001b[0m     flat_inputs, captured_inputs\u001b[39m=\u001b[39;49mfunction\u001b[39m.\u001b[39;49mcaptured_inputs\n\u001b[0;32m    141\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\totol\\miniconda3\\envs\\env2\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1264\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1260\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1261\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1262\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1263\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1264\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mflat_call(args)\n\u001b[0;32m   1265\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1266\u001b[0m     args,\n\u001b[0;32m   1267\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1268\u001b[0m     executing_eagerly)\n\u001b[0;32m   1269\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\totol\\miniconda3\\envs\\env2\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:217\u001b[0m, in \u001b[0;36mAtomicFunction.flat_call\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mflat_call\u001b[39m(\u001b[39mself\u001b[39m, args: Sequence[core\u001b[39m.\u001b[39mTensor]) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[0;32m    216\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Calls with tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 217\u001b[0m   flat_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m(\u001b[39m*\u001b[39;49margs)\n\u001b[0;32m    218\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction_type\u001b[39m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[1;32mc:\\Users\\totol\\miniconda3\\envs\\env2\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:252\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    250\u001b[0m \u001b[39mwith\u001b[39;00m record\u001b[39m.\u001b[39mstop_recording():\n\u001b[0;32m    251\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bound_context\u001b[39m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 252\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_bound_context\u001b[39m.\u001b[39;49mcall_function(\n\u001b[0;32m    253\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname,\n\u001b[0;32m    254\u001b[0m         \u001b[39mlist\u001b[39;49m(args),\n\u001b[0;32m    255\u001b[0m         \u001b[39mlen\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction_type\u001b[39m.\u001b[39;49mflat_outputs),\n\u001b[0;32m    256\u001b[0m     )\n\u001b[0;32m    257\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    258\u001b[0m     outputs \u001b[39m=\u001b[39m make_call_op_in_graph(\n\u001b[0;32m    259\u001b[0m         \u001b[39mself\u001b[39m,\n\u001b[0;32m    260\u001b[0m         \u001b[39mlist\u001b[39m(args),\n\u001b[0;32m    261\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bound_context\u001b[39m.\u001b[39mfunction_call_options\u001b[39m.\u001b[39mas_attrs(),\n\u001b[0;32m    262\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\totol\\miniconda3\\envs\\env2\\lib\\site-packages\\tensorflow\\python\\eager\\context.py:1479\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1477\u001b[0m cancellation_context \u001b[39m=\u001b[39m cancellation\u001b[39m.\u001b[39mcontext()\n\u001b[0;32m   1478\u001b[0m \u001b[39mif\u001b[39;00m cancellation_context \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 1479\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m   1480\u001b[0m       name\u001b[39m.\u001b[39;49mdecode(\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m   1481\u001b[0m       num_outputs\u001b[39m=\u001b[39;49mnum_outputs,\n\u001b[0;32m   1482\u001b[0m       inputs\u001b[39m=\u001b[39;49mtensor_inputs,\n\u001b[0;32m   1483\u001b[0m       attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m   1484\u001b[0m       ctx\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[0;32m   1485\u001b[0m   )\n\u001b[0;32m   1486\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1487\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1488\u001b[0m       name\u001b[39m.\u001b[39mdecode(\u001b[39m\"\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[0;32m   1489\u001b[0m       num_outputs\u001b[39m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1493\u001b[0m       cancellation_manager\u001b[39m=\u001b[39mcancellation_context,\n\u001b[0;32m   1494\u001b[0m   )\n",
      "File \u001b[1;32mc:\\Users\\totol\\miniconda3\\envs\\env2\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:60\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     53\u001b[0m   \u001b[39m# Convert any objects of type core_types.Tensor to Tensor.\u001b[39;00m\n\u001b[0;32m     54\u001b[0m   inputs \u001b[39m=\u001b[39m [\n\u001b[0;32m     55\u001b[0m       tensor_conversion_registry\u001b[39m.\u001b[39mconvert(t)\n\u001b[0;32m     56\u001b[0m       \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(t, core_types\u001b[39m.\u001b[39mTensor)\n\u001b[0;32m     57\u001b[0m       \u001b[39melse\u001b[39;00m t\n\u001b[0;32m     58\u001b[0m       \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m inputs\n\u001b[0;32m     59\u001b[0m   ]\n\u001b[1;32m---> 60\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     61\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     62\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     63\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "# Définissez le callback de sauvegarde du modèle\n",
    "checkpoint = ModelCheckpoint('meilleur_modele.h5', monitor='val_accuracy', save_best_only=True)\n",
    "\n",
    "# Compilez le modèle\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Entraînez le modèle avec des batches de taille 10 par epoch et sauvegardez le meilleur modèle\n",
    "model.fit(data, labels, epochs=10, validation_split=0.20, batch_size=10, callbacks=[checkpoint])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_defect_multi_class(model, image_path):\n",
    "    preprocessed_img = load_and_preprocess_image(image_path)\n",
    "    predictions = model.predict(preprocessed_img)\n",
    "    print (model.predict(preprocessed_img))\n",
    "\n",
    "    # Interprétez les prédictions\n",
    "    class_labels = ['blobs', 'cracks', 'OK', 'spaghetti','under exstrosion']\n",
    "    predicted_class = class_labels[np.argmax(predictions)]\n",
    "\n",
    "    return predicted_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "[[5.9661060e-04 6.4443958e-07 9.9880850e-01 4.5445759e-04 1.9350654e-07\n",
      "  1.3600009e-04 3.8068251e-08 1.2353395e-07 1.1117997e-07 3.4085747e-06]]\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "[[9.7541037e-05 2.0789756e-13 3.9061911e-06 9.9989486e-01 1.7674442e-14\n",
      "  3.6850272e-06 2.4889755e-14 8.4983764e-15 1.5818092e-17 1.3814507e-13]]\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "[[1.74776673e-01 7.97825919e-07 4.58881631e-03 8.20184290e-01\n",
      "  5.18182510e-08 4.49096522e-04 1.66540914e-07 1.56985234e-08\n",
      "  6.48843423e-10 1.00521106e-07]]\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "[[2.0440410e-01 3.2438166e-08 5.7968730e-01 2.1489236e-01 4.0942902e-09\n",
      "  1.0162197e-03 4.7412687e-09 6.9255951e-10 4.5931497e-10 2.3398451e-08]]\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "[[1.1264557e-02 4.1479529e-14 9.0759257e-03 9.7963321e-01 6.7117547e-17\n",
      "  2.6287304e-05 1.8223584e-15 4.0988553e-17 7.2511800e-19 7.3588689e-15]]\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "[[2.3315316e-03 1.4132197e-06 1.5372643e-01 7.6347584e-01 3.8028219e-08\n",
      "  8.0462359e-02 6.5756302e-07 3.1059937e-08 1.5613212e-08 1.7241211e-06]]\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "[[6.2548977e-01 5.6613864e-10 2.0745717e-01 1.6705173e-01 8.1610231e-12\n",
      "  1.2922853e-06 3.2578048e-12 1.5301618e-12 1.9835551e-13 8.0460034e-11]]\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "[[4.2049225e-02 4.5159618e-10 2.3885728e-01 7.1909350e-01 7.7045427e-12\n",
      "  4.2281481e-08 2.1360522e-13 1.1023809e-12 6.3920732e-14 1.5834506e-10]]\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "[[2.2332938e-02 2.0364885e-09 5.5928244e-03 9.7207355e-01 3.3688247e-11\n",
      "  7.2640699e-07 1.3202877e-11 7.6543086e-12 6.1234378e-13 1.0607318e-10]]\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "[[2.1512967e-07 8.9840912e-12 9.8600751e-01 1.3984900e-02 3.2302563e-12\n",
      "  7.2831763e-06 1.5940672e-13 3.5340123e-12 2.5728500e-13 1.2092727e-09]]\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "[[1.21880230e-02 6.33842401e-09 4.44211334e-01 5.43591499e-01\n",
      "  5.27180188e-10 9.14399425e-06 1.06680706e-10 5.40992529e-11\n",
      "  1.07815128e-11 8.36233216e-09]]\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "[[8.0727832e-03 3.6889458e-10 9.8290378e-01 7.6817451e-03 4.1972020e-11\n",
      "  1.3417210e-03 9.4454167e-11 3.7172296e-12 2.4490551e-12 1.0407140e-09]]\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "[[1.0557739e-01 2.7336671e-09 4.1505787e-01 4.7927520e-01 3.1371120e-10\n",
      "  8.9537738e-05 2.1471733e-10 4.9178332e-11 6.8998917e-12 3.0040073e-09]]\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "[[8.3554812e-02 1.3497585e-07 8.9807868e-01 1.8345254e-02 1.8390505e-08\n",
      "  2.0995320e-05 5.1020299e-09 2.2097111e-09 2.1590090e-09 9.0851266e-08]]\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "[[8.2025686e-03 1.0476377e-07 6.2714684e-01 3.6456016e-01 1.3955691e-08\n",
      "  9.0133348e-05 4.6067532e-09 1.5574750e-09 8.7858054e-10 1.3901277e-07]]\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "[[2.2394685e-02 2.6334212e-07 5.5494976e-01 4.2249325e-01 9.2561185e-09\n",
      "  1.6195417e-04 7.5942372e-09 3.2013434e-09 1.0087953e-09 1.3486512e-07]]\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "[[1.7175351e-04 8.8538933e-11 9.6439493e-01 3.5430718e-02 3.8644825e-12\n",
      "  2.6254347e-06 8.2849022e-13 1.6399430e-12 1.0598855e-12 4.5006684e-10]]\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "[[1.6763438e-04 2.4167066e-09 7.6397657e-01 2.3584808e-01 1.1372526e-10\n",
      "  7.6473934e-06 1.4923085e-11 8.6151392e-11 1.6490458e-11 1.1271130e-08]]\n"
     ]
    }
   ],
   "source": [
    "resultf=\"\"\n",
    "nb_total=0\n",
    "nb_positif=0\n",
    "for filename in os.listdir(\"testperso\"):\n",
    "    #print(filename)\n",
    "    nb_total+=1\n",
    "\n",
    "    result = predict_defect_multi_class(model, \"testperso/\" + filename)\n",
    "    if result=='OK':\n",
    "        nb_positif+=1\n",
    "        \n",
    "    resultf= resultf + \"prédiction pour\"+ filename + \" : \"+ str(result) +\"\\n\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prédiction pourok.jpg : OK\n",
      "prédiction pourok3.jpg : spaghetti\n",
      "prédiction pourok4.jpg : spaghetti\n",
      "prédiction pourok5.png : OK\n",
      "prédiction pourspaghetti.jpg : spaghetti\n",
      "prédiction pourspaghetti2.jpeg : spaghetti\n",
      "prédiction pourWIN_20231010_15_02_24_Pro.jpg : blobs\n",
      "prédiction pourWIN_20231010_15_02_40_Pro.jpg : spaghetti\n",
      "prédiction pourWIN_20231010_15_03_00_Pro.jpg : spaghetti\n",
      "prédiction pourWIN_20231010_15_03_09_Pro.jpg : OK\n",
      "prédiction pourWIN_20231010_15_03_11_Pro.jpg : spaghetti\n",
      "prédiction pourWIN_20231010_15_03_18_Pro.jpg : OK\n",
      "prédiction pourWIN_20231010_15_03_24_Pro.jpg : spaghetti\n",
      "prédiction pourWIN_20231010_15_03_29_Pro.jpg : OK\n",
      "prédiction pourWIN_20231010_15_03_56_Pro.jpg : OK\n",
      "prédiction pourWIN_20231010_15_03_58_Pro.jpg : OK\n",
      "prédiction pourWIN_20231010_15_04_02_Pro.jpg : OK\n",
      "prédiction pourWIN_20231010_15_04_05_Pro.jpg : OK\n",
      "\n",
      "50.0 % de précision\n"
     ]
    }
   ],
   "source": [
    "print (resultf)\n",
    "print(str((nb_positif*100)/nb_total) + \" % de précision\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Photo capturée avec succès.\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "[[0.3253603  0.02096455 0.10515112 0.32017654 0.00685089 0.19232626\n",
      "  0.01053569 0.0048363  0.00487529 0.00892307]]\n",
      "Prédiction pour ok.jpg: blobs\n"
     ]
    }
   ],
   "source": [
    "# Ouvrir la webcam (la webcam par défaut a l'ID 0)\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Vérifier si la webcam est ouverte correctement\n",
    "if not cap.isOpened():\n",
    "    print(\"Erreur: Impossible d'ouvrir la webcam.\")\n",
    "    exit()\n",
    "\n",
    "# Capturer une image\n",
    "time.sleep(1)\n",
    "ret, frame = cap.read()\n",
    "\n",
    "# Sauvegarder l'image capturée\n",
    "if ret:\n",
    "    cv2.imwrite(\"photo_capturee.jpg\", frame)\n",
    "    print(\"Photo capturée avec succès.\")\n",
    "else:\n",
    "    print(\"Erreur lors de la capture de la photo.\")\n",
    "\n",
    "# Libérer la webcam\n",
    "cap.release()\n",
    "time.sleep(1)\n",
    "\n",
    "\n",
    "result = predict_defect_multi_class(model, 'photo_capturee.jpg')\n",
    "print(f\"Prédiction pour {image_path_to_predict}: {result}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ia",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
