{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import random\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://drive.google.com/drive/folders/1_MU7jTR0kTt8MFQYrUzWiWc6uM-BHG_9?usp=drive_link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(dataset_path):\n",
    "    data = []\n",
    "    labels = []\n",
    "\n",
    "    for folder in os.listdir(dataset_path):\n",
    "        folder_path = os.path.join(dataset_path, folder)\n",
    "        if os.path.isdir(folder_path):\n",
    "            label = 1 if folder.lower() == 'ok' else 0  # 1 for OK, 0 for defects\n",
    "            for filename in os.listdir(folder_path):\n",
    "                img_path = os.path.join(folder_path, filename)\n",
    "                img = cv2.imread(img_path)\n",
    "                img = cv2.resize(img, (128, 128))  # Adjust the size as needed\n",
    "                data.append(img)\n",
    "                labels.append(label)\n",
    "                \n",
    "    data = np.array(data) / 255.0  # Normalize pixel values\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    return data, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = 'dataset'\n",
    "data, labels = load_data(dataset_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "324\n"
     ]
    }
   ],
   "source": [
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 3)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "9/9 [==============================] - 4s 295ms/step - loss: 0.4042 - accuracy: 0.8108 - val_loss: 1.0875 - val_accuracy: 0.4615\n",
      "Epoch 2/10\n",
      "9/9 [==============================] - 3s 278ms/step - loss: 0.3580 - accuracy: 0.8571 - val_loss: 0.4670 - val_accuracy: 0.7846\n",
      "Epoch 3/10\n",
      "9/9 [==============================] - 2s 252ms/step - loss: 0.2725 - accuracy: 0.8996 - val_loss: 0.3408 - val_accuracy: 0.8000\n",
      "Epoch 4/10\n",
      "9/9 [==============================] - 2s 247ms/step - loss: 0.3005 - accuracy: 0.8958 - val_loss: 0.5987 - val_accuracy: 0.7385\n",
      "Epoch 5/10\n",
      "9/9 [==============================] - 2s 238ms/step - loss: 0.2109 - accuracy: 0.9305 - val_loss: 0.6808 - val_accuracy: 0.7231\n",
      "Epoch 6/10\n",
      "9/9 [==============================] - 2s 245ms/step - loss: 0.1723 - accuracy: 0.9382 - val_loss: 0.8069 - val_accuracy: 0.6769\n",
      "Epoch 7/10\n",
      "9/9 [==============================] - 2s 250ms/step - loss: 0.1443 - accuracy: 0.9537 - val_loss: 0.4313 - val_accuracy: 0.8000\n",
      "Epoch 8/10\n",
      "9/9 [==============================] - 2s 237ms/step - loss: 0.1159 - accuracy: 0.9730 - val_loss: 0.3467 - val_accuracy: 0.8615\n",
      "Epoch 9/10\n",
      "9/9 [==============================] - 2s 249ms/step - loss: 0.0914 - accuracy: 0.9807 - val_loss: 0.6483 - val_accuracy: 0.7385\n",
      "Epoch 10/10\n",
      "9/9 [==============================] - 2s 234ms/step - loss: 0.0669 - accuracy: 0.9846 - val_loss: 1.0008 - val_accuracy: 0.6154\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x139b9b1a6e0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(data, labels, epochs=10, validation_split=0.20)\n",
    "\n",
    "#model.save('defect_detection_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess_image(image_path):\n",
    "    img = cv2.imread(image_path)\n",
    "    img = cv2.resize(img, (128, 128))  # Assurez-vous que la taille correspond à celle utilisée lors de l'entraînement\n",
    "    img = img / 255.0  # Normalisez les valeurs des pixels\n",
    "    img = np.expand_dims(img, axis=0)  # Ajoutez une dimension pour représenter le lot (batch)\n",
    "\n",
    "    return img\n",
    "\n",
    "def predict_defect(model, image_path):\n",
    "    preprocessed_img = load_and_preprocess_image(image_path)\n",
    "    prediction = model.predict(preprocessed_img)\n",
    "\n",
    "    # Interprétez la prédiction (1 signifie \"OK\", 0 signifie \"défaut\")\n",
    "    if prediction[0, 0] > 0.5:\n",
    "        return \"OK\"\n",
    "    else:\n",
    "        return \"Défaut\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.8.1) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\resize.cpp:4062: error: (-215:Assertion failed) !ssize.empty() in function 'cv::resize'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\totol\\Mon Drive\\projet impression 3d\\projet.ipynb Cellule 8\u001b[0m line \u001b[0;36m6\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/totol/Mon%20Drive/projet%20impression%203d/projet.ipynb#X10sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Charger le modèle préalablement entraîné\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/totol/Mon%20Drive/projet%20impression%203d/projet.ipynb#X10sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39m#model = keras.models.load_model('defect_detection_model.h5')\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/totol/Mon%20Drive/projet%20impression%203d/projet.ipynb#X10sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/totol/Mon%20Drive/projet%20impression%203d/projet.ipynb#X10sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# Exemple d'utilisation\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/totol/Mon%20Drive/projet%20impression%203d/projet.ipynb#X10sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m image_path_to_predict \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mok.jpg\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/totol/Mon%20Drive/projet%20impression%203d/projet.ipynb#X10sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m result \u001b[39m=\u001b[39m predict_defect(model, image_path_to_predict)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/totol/Mon%20Drive/projet%20impression%203d/projet.ipynb#X10sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mPrédiction pour \u001b[39m\u001b[39m{\u001b[39;00mimage_path_to_predict\u001b[39m}\u001b[39;00m\u001b[39m: \u001b[39m\u001b[39m{\u001b[39;00mresult\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;32mc:\\Users\\totol\\Mon Drive\\projet impression 3d\\projet.ipynb Cellule 8\u001b[0m line \u001b[0;36m1\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/totol/Mon%20Drive/projet%20impression%203d/projet.ipynb#X10sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredict_defect\u001b[39m(model, image_path):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/totol/Mon%20Drive/projet%20impression%203d/projet.ipynb#X10sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     preprocessed_img \u001b[39m=\u001b[39m load_and_preprocess_image(image_path)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/totol/Mon%20Drive/projet%20impression%203d/projet.ipynb#X10sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     prediction \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict(preprocessed_img)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/totol/Mon%20Drive/projet%20impression%203d/projet.ipynb#X10sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     \u001b[39m# Interprétez la prédiction (1 signifie \"OK\", 0 signifie \"défaut\")\u001b[39;00m\n",
      "\u001b[1;32mc:\\Users\\totol\\Mon Drive\\projet impression 3d\\projet.ipynb Cellule 8\u001b[0m line \u001b[0;36m3\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/totol/Mon%20Drive/projet%20impression%203d/projet.ipynb#X10sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload_and_preprocess_image\u001b[39m(image_path):\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/totol/Mon%20Drive/projet%20impression%203d/projet.ipynb#X10sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     img \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mimread(image_path)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/totol/Mon%20Drive/projet%20impression%203d/projet.ipynb#X10sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     img \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39;49mresize(img, (\u001b[39m128\u001b[39;49m, \u001b[39m128\u001b[39;49m))  \u001b[39m# Assurez-vous que la taille correspond à celle utilisée lors de l'entraînement\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/totol/Mon%20Drive/projet%20impression%203d/projet.ipynb#X10sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     img \u001b[39m=\u001b[39m img \u001b[39m/\u001b[39m \u001b[39m255.0\u001b[39m  \u001b[39m# Normalisez les valeurs des pixels\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/totol/Mon%20Drive/projet%20impression%203d/projet.ipynb#X10sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     img \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mexpand_dims(img, axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)  \u001b[39m# Ajoutez une dimension pour représenter le lot (batch)\u001b[39;00m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.8.1) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\resize.cpp:4062: error: (-215:Assertion failed) !ssize.empty() in function 'cv::resize'\n"
     ]
    }
   ],
   "source": [
    "# Charger le modèle préalablement entraîné\n",
    "#model = keras.models.load_model('defect_detection_model.h5')\n",
    "\n",
    "# Exemple d'utilisation\n",
    "image_path_to_predict = 'ok.jpg'\n",
    "result = predict_defect(model, image_path_to_predict)\n",
    "print(f\"Prédiction pour {image_path_to_predict}: {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 82ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n"
     ]
    }
   ],
   "source": [
    "resultf=\"\"\n",
    "for filename in os.listdir(\"testperso\"):\n",
    "    #print(filename)\n",
    "    result = predict_defect(model, \"testperso/\" + filename)\n",
    "    resultf= resultf + \"prédiction pour\"+ filename + \" : \"+ str(result) +\"\\n\"\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prédiction pourWIN_20231010_15_02_24_Pro.jpg : Défaut\n",
      "prédiction pourWIN_20231010_15_02_40_Pro.jpg : Défaut\n",
      "prédiction pourWIN_20231010_15_03_00_Pro.jpg : Défaut\n",
      "prédiction pourWIN_20231010_15_03_09_Pro.jpg : Défaut\n",
      "prédiction pourWIN_20231010_15_03_11_Pro.jpg : Défaut\n",
      "prédiction pourWIN_20231010_15_03_18_Pro.jpg : Défaut\n",
      "prédiction pourWIN_20231010_15_03_24_Pro.jpg : OK\n",
      "prédiction pourWIN_20231010_15_03_29_Pro.jpg : Défaut\n",
      "prédiction pourWIN_20231010_15_03_56_Pro.jpg : Défaut\n",
      "prédiction pourWIN_20231010_15_03_58_Pro.jpg : Défaut\n",
      "prédiction pourWIN_20231010_15_04_02_Pro.jpg : Défaut\n",
      "prédiction pourWIN_20231010_15_04_05_Pro.jpg : Défaut\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print (resultf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "multi classes-----------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess_image(image_path):\n",
    "    img = cv2.imread(image_path)\n",
    "    img = cv2.resize(img, (128, 128))  # Assurez-vous que la taille correspond à celle utilisée lors de l'entraînement\n",
    "    img = img / 255.0  # Normalisez les valeurs des pixels\n",
    "    img = np.expand_dims(img, axis=0)  # Ajoutez une dimension pour représenter le lot (batch)\n",
    "\n",
    "    return img\n",
    "\n",
    "def predict_defect(model, image_path):\n",
    "    preprocessed_img = load_and_preprocess_image(image_path)\n",
    "    prediction = model.predict(preprocessed_img)\n",
    "\n",
    "    # Interprétez la prédiction (1 signifie \"OK\", 0 signifie \"défaut\")\n",
    "    if prediction[0, 0] > 0.5:\n",
    "        return \"OK\"\n",
    "    else:\n",
    "        return \"Défaut\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_multi_class(dataset_path):\n",
    "    data = []\n",
    "    labels = []\n",
    "\n",
    "    for folder in os.listdir(dataset_path):\n",
    "        folder_path = os.path.join(dataset_path, folder)\n",
    "        if os.path.isdir(folder_path):\n",
    "            \n",
    "            label = folder.lower()  # Utilisez le nom du dossier comme label\n",
    "            print(label)\n",
    "            for filename in os.listdir(folder_path):\n",
    "                img_path = os.path.join(folder_path, filename)\n",
    "                img = cv2.imread(img_path)\n",
    "                img = cv2.resize(img, (128, 128))\n",
    "                data.append(img)\n",
    "                labels.append(label)\n",
    "\n",
    "    data = np.array(data) / 255.0\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    return data, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blobs\n",
      "cracks\n",
      "ok\n",
      "spaghetti\n",
      "stringing\n",
      "under exstrosion\n"
     ]
    }
   ],
   "source": [
    "dataset_path = 'dataset'\n",
    "data, labels = load_data_multi_class(dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définir un dictionnaire de mapping catégorie -> numéro\n",
    "categorie_mapping = {\n",
    "    \"blobs\": 0,\n",
    "    \"cracks\": 1,\n",
    "    \"ok\": 2,\n",
    "    \"spaghetti\": 3,\n",
    "    \"stringing\": 4,\n",
    "    \"under exstrosion\": 5\n",
    "}\n",
    "\n",
    "# Utiliser NumPy pour convertir les catégories en numéros\n",
    "labels = np.array([categorie_mapping[c] for c in labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "324\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "print (len(labels))\n",
    "print(labels[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "324\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "combined_data = list(zip(data,labels))\n",
    "\n",
    "# Mélangez la liste combinée\n",
    "random.shuffle(combined_data)\n",
    "\n",
    "# Divisez à nouveau la liste combinée en deux listes distinctes\n",
    "data,labels = zip(*combined_data)\n",
    "\n",
    "labels = np.array(labels)\n",
    "data = np.array(data)\n",
    "print (len(labels))\n",
    "print(labels[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 3)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dropout(0.5),  # Ajout de la couche Dropout\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dropout(0.5),  # Ajout d'une autre couche Dropout\n",
    "    layers.Dense(10, activation='softmax')  # Ajustez cela en fonction de votre nombre de classes\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "259.2\n"
     ]
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "26/26 [==============================] - 5s 163ms/step - loss: 0.2009 - accuracy: 0.9575 - val_loss: 2.6285 - val_accuracy: 0.3538\n",
      "Epoch 2/10\n",
      "26/26 [==============================] - 4s 144ms/step - loss: 0.1539 - accuracy: 0.9498 - val_loss: 2.3858 - val_accuracy: 0.3692\n",
      "Epoch 3/10\n",
      "26/26 [==============================] - 4s 149ms/step - loss: 0.1376 - accuracy: 0.9653 - val_loss: 3.3681 - val_accuracy: 0.3846\n",
      "Epoch 4/10\n",
      "26/26 [==============================] - 4s 155ms/step - loss: 0.1189 - accuracy: 0.9691 - val_loss: 2.9669 - val_accuracy: 0.3231\n",
      "Epoch 5/10\n",
      "26/26 [==============================] - 4s 153ms/step - loss: 0.1050 - accuracy: 0.9730 - val_loss: 3.7586 - val_accuracy: 0.3231\n",
      "Epoch 6/10\n",
      "26/26 [==============================] - 4s 151ms/step - loss: 0.0884 - accuracy: 0.9768 - val_loss: 3.9973 - val_accuracy: 0.4000\n",
      "Epoch 7/10\n",
      "26/26 [==============================] - 4s 155ms/step - loss: 0.0648 - accuracy: 0.9846 - val_loss: 3.6161 - val_accuracy: 0.4000\n",
      "Epoch 8/10\n",
      "26/26 [==============================] - 4s 147ms/step - loss: 0.0718 - accuracy: 0.9768 - val_loss: 3.8857 - val_accuracy: 0.4000\n",
      "Epoch 9/10\n",
      "26/26 [==============================] - 4s 145ms/step - loss: 0.0626 - accuracy: 0.9846 - val_loss: 3.5356 - val_accuracy: 0.3846\n",
      "Epoch 10/10\n",
      "26/26 [==============================] - 4s 145ms/step - loss: 0.0401 - accuracy: 0.9923 - val_loss: 3.7214 - val_accuracy: 0.3538\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x139b9c675b0>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Compilez le modèle\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Entraînez le modèle\n",
    "\n",
    "model.fit(data, labels, epochs=10, validation_split=0.20, batch_size=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_defect_multi_class(model, image_path):\n",
    "    preprocessed_img = load_and_preprocess_image(image_path)\n",
    "    predictions = model.predict(preprocessed_img)\n",
    "    print (model.predict(preprocessed_img))\n",
    "\n",
    "    # Interprétez les prédictions\n",
    "    class_labels = ['blobs', 'cracks', 'OK', 'spaghetti','under exstrosion']\n",
    "    predicted_class = class_labels[np.argmax(predictions)]\n",
    "\n",
    "    return predicted_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "[[3.5722216e-04 2.1220310e-05 9.8947161e-01 1.9746816e-03 6.8374928e-03\n",
      "  1.3376599e-03 1.5739394e-09 2.9612368e-08 3.3252301e-09 8.2533829e-09]]\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "[[3.9721108e-06 2.3858815e-09 9.9990046e-01 8.9471810e-05 5.7368297e-06\n",
      "  3.6077688e-07 6.5878669e-17 5.7095916e-14 5.0846150e-17 1.7270075e-15]]\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "[[2.2435676e-04 1.8971813e-08 9.9709177e-01 1.6477639e-03 1.0332337e-03\n",
      "  2.9194962e-06 4.8622440e-13 2.3878970e-11 2.0624945e-13 4.5924419e-12]]\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "[[7.5437260e-05 6.4280332e-09 1.0377671e-02 1.7039272e-07 9.8954672e-01\n",
      "  2.6728662e-08 9.2237606e-17 1.1863405e-14 5.3128477e-17 1.7707797e-15]]\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "[[5.7595023e-03 3.6498182e-10 9.3074250e-01 6.3492529e-02 3.7928353e-07\n",
      "  5.0542021e-06 1.4904836e-18 3.8932536e-17 1.7266045e-19 1.1036398e-17]]\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "[[2.5198553e-04 5.7003210e-05 8.4517282e-01 1.1734090e-01 8.1789866e-04\n",
      "  3.6359202e-02 1.9059595e-08 1.9801057e-07 6.9765753e-09 2.4427116e-08]]\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "[[5.5348297e-04 9.2031325e-09 7.8225072e-04 4.2436420e-04 9.9820232e-01\n",
      "  3.7530703e-05 5.8314591e-18 1.6212871e-15 1.3461454e-17 2.0036259e-16]]\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "[[9.5716256e-05 2.3828293e-09 4.5003079e-02 9.5486873e-01 2.7308648e-05\n",
      "  5.1729853e-06 1.5194798e-16 9.7308966e-15 2.5514054e-16 4.1417505e-16]]\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "[[2.55652435e-06 9.67208109e-08 1.26929845e-05 9.95756209e-01\n",
      "  3.83675680e-03 3.91651032e-04 7.46031976e-15 1.23643432e-14\n",
      "  3.51212873e-15 1.54558881e-14]]\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "[[2.9362893e-08 8.3178957e-06 9.0726542e-01 9.2586346e-02 5.1654406e-05\n",
      "  8.8245928e-05 2.5711920e-13 1.3849427e-12 1.1406751e-12 2.5484340e-14]]\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "[[2.0897990e-09 2.9664394e-12 9.9997950e-01 2.0159523e-05 3.5209933e-07\n",
      "  1.8396880e-09 3.3992991e-17 1.9292175e-15 2.6162447e-17 4.2907615e-17]]\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "[[6.7605154e-04 1.3625517e-07 9.8011065e-01 1.3030476e-04 1.8173441e-02\n",
      "  9.0943580e-04 3.5614186e-15 8.1469239e-13 9.5366338e-15 8.4977049e-14]]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "[[3.1519495e-04 1.0603750e-10 9.9968302e-01 1.0788871e-06 5.7768716e-07\n",
      "  7.1636265e-08 4.8792269e-16 5.7193250e-14 1.5035261e-16 1.6230798e-14]]\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "[[2.7251834e-02 2.8121897e-07 9.7009689e-01 2.3757108e-03 2.5578740e-04\n",
      "  1.9454963e-05 7.4230926e-13 3.6053240e-11 1.8272616e-13 6.0779528e-12]]\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "[[1.9066678e-06 2.8051893e-08 9.9590957e-01 4.0834644e-03 4.6897471e-06\n",
      "  3.2741565e-07 3.7275787e-13 3.2965061e-12 3.3014376e-13 6.0609102e-13]]\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "[[9.6058883e-03 7.2869699e-04 9.5072693e-01 2.3858342e-02 1.4800038e-02\n",
      "  2.8007230e-04 2.8180600e-10 2.5103972e-09 5.6791244e-10 1.5109507e-09]]\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "[[2.2649519e-05 5.8301342e-08 2.3287937e-01 5.3469057e-04 7.6656258e-01\n",
      "  5.5270004e-07 1.1012093e-14 4.2289929e-13 6.5013688e-15 6.8708006e-14]]\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "[[3.3726570e-05 6.7279907e-05 4.9274042e-01 2.5194177e-01 3.9483793e-02\n",
      "  2.1573308e-01 6.8526599e-12 5.1569592e-11 5.7407926e-11 6.1537078e-12]]\n"
     ]
    }
   ],
   "source": [
    "resultf=\"\"\n",
    "nb_total=0\n",
    "nb_positif=0\n",
    "for filename in os.listdir(\"testperso\"):\n",
    "    #print(filename)\n",
    "    nb_total+=1\n",
    "\n",
    "    result = predict_defect_multi_class(model, \"testperso/\" + filename)\n",
    "    if result=='OK':\n",
    "        nb_positif+=1\n",
    "        \n",
    "    resultf= resultf + \"prédiction pour\"+ filename + \" : \"+ str(result) +\"\\n\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prédiction pourok.jpg : OK\n",
      "prédiction pourok3.jpg : OK\n",
      "prédiction pourok4.jpg : OK\n",
      "prédiction pourok5.png : under exstrosion\n",
      "prédiction pourspaghetti.jpg : OK\n",
      "prédiction pourspaghetti2.jpeg : OK\n",
      "prédiction pourWIN_20231010_15_02_24_Pro.jpg : under exstrosion\n",
      "prédiction pourWIN_20231010_15_02_40_Pro.jpg : spaghetti\n",
      "prédiction pourWIN_20231010_15_03_00_Pro.jpg : spaghetti\n",
      "prédiction pourWIN_20231010_15_03_09_Pro.jpg : OK\n",
      "prédiction pourWIN_20231010_15_03_11_Pro.jpg : OK\n",
      "prédiction pourWIN_20231010_15_03_18_Pro.jpg : OK\n",
      "prédiction pourWIN_20231010_15_03_24_Pro.jpg : OK\n",
      "prédiction pourWIN_20231010_15_03_29_Pro.jpg : OK\n",
      "prédiction pourWIN_20231010_15_03_56_Pro.jpg : OK\n",
      "prédiction pourWIN_20231010_15_03_58_Pro.jpg : OK\n",
      "prédiction pourWIN_20231010_15_04_02_Pro.jpg : under exstrosion\n",
      "prédiction pourWIN_20231010_15_04_05_Pro.jpg : OK\n",
      "\n",
      "72.22222222222223 % de précision\n"
     ]
    }
   ],
   "source": [
    "print (resultf)\n",
    "print(str((nb_positif*100)/nb_total) + \" % de précision\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Photo capturée avec succès.\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "[[3.4101017e-02 5.2544610e-03 9.1146988e-01 1.8071422e-02 1.5108110e-02\n",
      "  1.5050286e-02 2.2792644e-04 2.9491232e-04 1.6262161e-04 2.5927747e-04]]\n",
      "Prédiction pour ok.jpg: OK\n"
     ]
    }
   ],
   "source": [
    "# Ouvrir la webcam (la webcam par défaut a l'ID 0)\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Vérifier si la webcam est ouverte correctement\n",
    "if not cap.isOpened():\n",
    "    print(\"Erreur: Impossible d'ouvrir la webcam.\")\n",
    "    exit()\n",
    "\n",
    "# Capturer une image\n",
    "time.sleep(1)\n",
    "ret, frame = cap.read()\n",
    "\n",
    "# Sauvegarder l'image capturée\n",
    "if ret:\n",
    "    cv2.imwrite(\"photo_capturee.jpg\", frame)\n",
    "    print(\"Photo capturée avec succès.\")\n",
    "else:\n",
    "    print(\"Erreur lors de la capture de la photo.\")\n",
    "\n",
    "# Libérer la webcam\n",
    "cap.release()\n",
    "time.sleep(1)\n",
    "\n",
    "\n",
    "result = predict_defect_multi_class(model, 'photo_capturee.jpg')\n",
    "print(f\"Prédiction pour {image_path_to_predict}: {result}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ia",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
